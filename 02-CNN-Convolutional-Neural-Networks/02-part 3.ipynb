{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea6daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bd130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get Id of default device\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0\n",
    "torch.cuda.get_device_name(0) # Get name device with ID '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccbe2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the current GPU memory usage by \n",
    "# tensors in bytes for a given device\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the current GPU memory managed by the\n",
    "# caching allocator in bytes for a given device\n",
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "a = torch.FloatTensor([1.,2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4947e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.device #find which device is being used(CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "a = torch.FloatTensor([1., 2.]).cuda() # .cuda would make it used CUDA instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eecebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated() #512 MB memory is being allocated now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa863968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.out = nn.Linear(h2, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205837bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the discussions here: discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpumodel = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(gpumodel.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d17db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Owner/Downloads/Udemy/Pytorch/iris.csv')\n",
    "# Split the data into features and target\n",
    "X = df.drop('variety',axis=1).values\n",
    "y = df['variety'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c5d5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train_torch = X_train.to(device)\n",
    "X_test_torch = X_test.to(device)\n",
    "y_train_torch = torch.tensor(y_train_le, dtype=torch.long).to(device)\n",
    "y_test_torch = torch.tensor(y_test_le, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f83f8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(X_train, batch_size=60, shuffle=True,pin_memory=True)\n",
    "testloader = DataLoader(X_test, batch_size=60, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "439311ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e7ea12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss: 0.04595106\n",
      "epoch: 11  loss: 0.04571902\n",
      "epoch: 21  loss: 0.04548763\n",
      "epoch: 31  loss: 0.04525835\n",
      "epoch: 41  loss: 0.04503223\n",
      "epoch: 51  loss: 0.04481002\n",
      "epoch: 61  loss: 0.04459254\n",
      "epoch: 71  loss: 0.04438039\n",
      "epoch: 81  loss: 0.04417421\n",
      "epoch: 91  loss: 0.04397450\n",
      "TOTAL TRAINING TIME: 0.13001656532287598\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 100\n",
    "losses = []\n",
    "start = time.time()\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = gpumodel.forward(X_train_torch.cuda())\n",
    "    loss = criterion(y_pred, y_train_torch.cuda())\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(f'TOTAL TRAINING TIME: {time.time()-start}')\n",
    "\n",
    "#This will ensure that all tensors and the model are on the same device (the GPU, in this case), allowing PyTorch to perform the operations correctly. Note that the .cuda() calls are necessary only when working on a machine with a CUDA-compatible GPU. If you're working on a machine without a GPU, keep the tensors on the CPU by omitting the .cuda() calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82ef0780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([-13.2271,   7.0168,  -2.1098], device='cuda:0') 1\n",
      " 2. tensor([-13.3811,   7.8008,  -2.7396], device='cuda:0') 1\n",
      " 3. tensor([ 16.5113,   3.0487, -13.1177], device='cuda:0') 0\n",
      " 4. tensor([-19.1503,   6.2611,   0.7067], device='cuda:0') 1\n",
      " 5. tensor([-30.2820,   3.7052,   6.9888], device='cuda:0') 2\n",
      " 6. tensor([-40.0698,   0.4675,  13.0620], device='cuda:0') 2\n",
      " 7. tensor([ 15.9038,   3.2489, -13.0625], device='cuda:0') 0\n",
      " 8. tensor([ 18.2580,   2.9889, -13.9614], device='cuda:0') 0\n",
      " 9. tensor([-30.5461,   3.4989,   7.2078], device='cuda:0') 2\n",
      "10. tensor([-37.4076,   1.9264,  11.0303], device='cuda:0') 2\n",
      "11. tensor([-38.5687,   1.5563,  11.7180], device='cuda:0') 2\n",
      "12. tensor([ 16.8079,   2.7965, -12.9399], device='cuda:0') 0\n",
      "13. tensor([-36.5900,   1.4215,  11.0986], device='cuda:0') 2\n",
      "14. tensor([-18.9548,   6.0786,   0.7875], device='cuda:0') 1\n",
      "15. tensor([-32.0045,   3.0253,   8.1244], device='cuda:0') 2\n",
      "16. tensor([-12.9605,   7.6847,  -2.7830], device='cuda:0') 1\n",
      "17. tensor([-24.7296,   4.3139,   4.3855], device='cuda:0') 2\n",
      "18. tensor([ 18.5880,   3.0395, -14.2028], device='cuda:0') 0\n",
      "19. tensor([-18.5006,   6.1648,   0.5098], device='cuda:0') 1\n",
      "20. tensor([-33.5443,   3.6268,   8.1924], device='cuda:0') 2\n",
      "21. tensor([ 17.5950,   3.0034, -13.6303], device='cuda:0') 0\n",
      "22. tensor([ 19.0263,   3.1931, -14.6383], device='cuda:0') 0\n",
      "23. tensor([-37.6107,   1.5551,  11.3603], device='cuda:0') 2\n",
      "24. tensor([ 17.5783,   2.9335, -13.5287], device='cuda:0') 0\n",
      "25. tensor([-28.2630,   3.8406,   6.1567], device='cuda:0') 2\n",
      "26. tensor([-25.7008,   4.2652,   4.7980], device='cuda:0') 2\n",
      "27. tensor([-17.2475,   6.4449,  -0.1584], device='cuda:0') 1\n",
      "28. tensor([-11.2317,   7.4651,  -3.3025], device='cuda:0') 1\n",
      "29. tensor([-30.5421,   3.3235,   7.3541], device='cuda:0') 2\n",
      "30. tensor([-28.0197,   3.5471,   6.2464], device='cuda:0') 2\n",
      "\n",
      "30 out of 30 = 100.00% correct\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test_torch):\n",
    "        y_val = gpumodel.forward(data)\n",
    "        print(f'{i+1:2}. {str(y_val):38} {y_test_torch[i]}')\n",
    "        if y_val.argmax().item() == y_test_torch[i]:\n",
    "            correct += 1\n",
    "print(f'\\n{correct} out of {len(y_test_torch)} = {100*correct/len(y_test_torch):.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29665c-10e5-4ac5-a549-bc875cc0a2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
